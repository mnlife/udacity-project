{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "train_filenames = os.listdir('train')\n",
    "train_cat = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "train_dog = filter(lambda x:x[:3] == 'dog', train_filenames)\n",
    "\n",
    "def rmrf_mkdir(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "rmrf_mkdir('train2')\n",
    "os.mkdir('train2/cat')\n",
    "os.mkdir('train2/dog')\n",
    "\n",
    "rmrf_mkdir('test2')\n",
    "os.symlink('../test/', 'test2/test')\n",
    "\n",
    "for filename in train_cat:\n",
    "    os.symlink('../../train/'+filename, 'train2/cat/'+filename)\n",
    "\n",
    "for filename in train_dog:\n",
    "    os.symlink('../../train/'+filename, 'train2/dog/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 96s 1us/step\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 63s 1us/step\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import h5py\n",
    "\n",
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "        \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator(\n",
    "        rotation_range=40)\n",
    "    #,\n",
    "    #    width_shift_range = 0.2,\n",
    "    #    height_shift_range = 0.2,\n",
    "   #     shear_range = 0.2,\n",
    "     #   zoom_range = 0.2,\n",
    "     #   horizontal_flip = True,\n",
    "     #   vertical_flip = True,\n",
    "     #   fill_mode= 'nearest')\n",
    "    test_gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(\"train2\", image_size, shuffle=False, \n",
    "                                              batch_size=16,class_mode='binary')\n",
    "    test_generator = test_gen.flow_from_directory(\"test2\", image_size, shuffle=False, \n",
    "                                             batch_size=16, class_mode='binary')\n",
    "\n",
    "    train = model.predict_generator(train_generator)\n",
    "    test = model.predict_generator(test_generator)\n",
    "    with h5py.File(\"gap_%s.h5\"%MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "\n",
    "write_gap(InceptionResNetV2, (299, 299), inception_resnet_v2.preprocess_input)\n",
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "write_gap(Xception, (299, 299), xception.preprocess_input)\n",
    "#write_gap(DenseNet201, (224, 224))\n",
    "#write_gap(VGG19, (224, 224), vgg19.preprocess_input)\n",
    "#write_gap(ResNet50, (224, 224), resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnlife/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2018)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"gap_InceptionResNetV2.h5\", \"gap_Xception.h5\", \"gap_InceptionV3.h5\"]:#, \"gap_ResNet50.h5\", \"gap_VGG19.h5\", \"gap_DenseNet201.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adadelta\n",
    "np.random.seed(2018)\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "#x = BatchNormalization(axis=3, scale=False, name='_bn')(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "#model.compile(optimizer='adadelta',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "#model.compile(optimizer='Adam', loss = 'binary_crossentropy', metrics = [\"accuracy\"])\n",
    "model.compile(optimizer=Adadelta(lr=0.005), loss = 'binary_crossentropy', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5632)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5632)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              5768192   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 6,030,849\n",
      "Trainable params: 6,030,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 5s 237us/step - loss: 0.5460 - acc: 0.7214 - val_loss: 0.2126 - val_acc: 0.9868\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.2620 - acc: 0.9131 - val_loss: 0.0921 - val_acc: 0.9866\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.1555 - acc: 0.9576 - val_loss: 0.0572 - val_acc: 0.9878\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 4s 208us/step - loss: 0.1141 - acc: 0.9690 - val_loss: 0.0444 - val_acc: 0.9880\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0906 - acc: 0.9743 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0771 - acc: 0.9779 - val_loss: 0.0348 - val_acc: 0.9892\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 4s 208us/step - loss: 0.0679 - acc: 0.9818 - val_loss: 0.0325 - val_acc: 0.9890\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0628 - acc: 0.9825 - val_loss: 0.0310 - val_acc: 0.9898\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0582 - acc: 0.9831 - val_loss: 0.0300 - val_acc: 0.9900\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0544 - acc: 0.9841 - val_loss: 0.0291 - val_acc: 0.9908\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0554 - acc: 0.9834 - val_loss: 0.0285 - val_acc: 0.9908\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0513 - acc: 0.9844 - val_loss: 0.0281 - val_acc: 0.9912\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0479 - acc: 0.9855 - val_loss: 0.0278 - val_acc: 0.9906\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0472 - acc: 0.9855 - val_loss: 0.0275 - val_acc: 0.9910\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0457 - acc: 0.9855 - val_loss: 0.0274 - val_acc: 0.9904\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0448 - acc: 0.9869 - val_loss: 0.0273 - val_acc: 0.9902\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0426 - acc: 0.9868 - val_loss: 0.0271 - val_acc: 0.9908\n",
      "Epoch 18/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0432 - acc: 0.9868 - val_loss: 0.0270 - val_acc: 0.9904\n",
      "Epoch 19/100\n",
      "20000/20000 [==============================] - 4s 211us/step - loss: 0.0416 - acc: 0.9869 - val_loss: 0.0271 - val_acc: 0.9910\n",
      "Epoch 20/100\n",
      "20000/20000 [==============================] - 4s 213us/step - loss: 0.0420 - acc: 0.9869 - val_loss: 0.0270 - val_acc: 0.9906\n",
      "Epoch 21/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0428 - acc: 0.9866 - val_loss: 0.0268 - val_acc: 0.9904\n",
      "Epoch 22/100\n",
      "20000/20000 [==============================] - 4s 213us/step - loss: 0.0379 - acc: 0.9878 - val_loss: 0.0268 - val_acc: 0.9908\n",
      "Epoch 23/100\n",
      "20000/20000 [==============================] - 4s 211us/step - loss: 0.0401 - acc: 0.9877 - val_loss: 0.0267 - val_acc: 0.9904\n",
      "Epoch 24/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0392 - acc: 0.9878 - val_loss: 0.0271 - val_acc: 0.9906\n",
      "Epoch 25/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0392 - acc: 0.9884 - val_loss: 0.0268 - val_acc: 0.9906\n",
      "Epoch 26/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0376 - acc: 0.9883 - val_loss: 0.0268 - val_acc: 0.9904\n",
      "Epoch 27/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0373 - acc: 0.9893 - val_loss: 0.0267 - val_acc: 0.9902\n",
      "Epoch 28/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0358 - acc: 0.9891 - val_loss: 0.0271 - val_acc: 0.9906\n",
      "Epoch 29/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0365 - acc: 0.9885 - val_loss: 0.0271 - val_acc: 0.9906\n",
      "Epoch 30/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0348 - acc: 0.9891 - val_loss: 0.0268 - val_acc: 0.9902\n",
      "Epoch 31/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0363 - acc: 0.9888 - val_loss: 0.0268 - val_acc: 0.9902\n",
      "Epoch 32/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0362 - acc: 0.9886 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "Epoch 33/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0326 - acc: 0.9909 - val_loss: 0.0268 - val_acc: 0.9902\n",
      "Epoch 34/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0345 - acc: 0.9888 - val_loss: 0.0266 - val_acc: 0.9902\n",
      "Epoch 35/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0337 - acc: 0.9894 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 36/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0359 - acc: 0.9886 - val_loss: 0.0270 - val_acc: 0.9914\n",
      "Epoch 37/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0322 - acc: 0.9897 - val_loss: 0.0269 - val_acc: 0.9910\n",
      "Epoch 38/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0313 - acc: 0.9899 - val_loss: 0.0269 - val_acc: 0.9908\n",
      "Epoch 39/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0325 - acc: 0.9890 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 40/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0358 - acc: 0.9883 - val_loss: 0.0272 - val_acc: 0.9908\n",
      "Epoch 41/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0334 - acc: 0.9890 - val_loss: 0.0270 - val_acc: 0.9910\n",
      "Epoch 42/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0330 - acc: 0.9897 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "Epoch 43/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0294 - acc: 0.9908 - val_loss: 0.0269 - val_acc: 0.9910\n",
      "Epoch 44/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0329 - acc: 0.9896 - val_loss: 0.0270 - val_acc: 0.9912\n",
      "Epoch 45/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0269 - val_acc: 0.9912\n",
      "Epoch 46/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0300 - acc: 0.9905 - val_loss: 0.0276 - val_acc: 0.9910\n",
      "Epoch 47/100\n",
      "20000/20000 [==============================] - 4s 213us/step - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0279 - val_acc: 0.9906\n",
      "Epoch 48/100\n",
      "20000/20000 [==============================] - 4s 214us/step - loss: 0.0311 - acc: 0.9900 - val_loss: 0.0271 - val_acc: 0.9908\n",
      "Epoch 49/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0321 - acc: 0.9895 - val_loss: 0.0271 - val_acc: 0.9910\n",
      "Epoch 50/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0326 - acc: 0.9888 - val_loss: 0.0275 - val_acc: 0.9910\n",
      "Epoch 51/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0315 - acc: 0.9892 - val_loss: 0.0273 - val_acc: 0.9910\n",
      "Epoch 52/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0299 - acc: 0.9910 - val_loss: 0.0274 - val_acc: 0.9908\n",
      "Epoch 53/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0324 - acc: 0.9899 - val_loss: 0.0267 - val_acc: 0.9912\n",
      "Epoch 54/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0308 - acc: 0.9905 - val_loss: 0.0269 - val_acc: 0.9914\n",
      "Epoch 55/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0292 - acc: 0.9908 - val_loss: 0.0273 - val_acc: 0.9912\n",
      "Epoch 56/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0285 - acc: 0.9907 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 57/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0303 - acc: 0.9901 - val_loss: 0.0269 - val_acc: 0.9914\n",
      "Epoch 58/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0303 - acc: 0.9899 - val_loss: 0.0270 - val_acc: 0.9914\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 4s 217us/step - loss: 0.0299 - acc: 0.9896 - val_loss: 0.0280 - val_acc: 0.9908\n",
      "Epoch 60/100\n",
      "20000/20000 [==============================] - 4s 209us/step - loss: 0.0331 - acc: 0.9890 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "Epoch 61/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0302 - acc: 0.9901 - val_loss: 0.0270 - val_acc: 0.9914\n",
      "Epoch 62/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0295 - acc: 0.9905 - val_loss: 0.0270 - val_acc: 0.9916\n",
      "Epoch 63/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0272 - val_acc: 0.9908\n",
      "Epoch 64/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0298 - acc: 0.9900 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "Epoch 65/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0299 - acc: 0.9905 - val_loss: 0.0268 - val_acc: 0.9918\n",
      "Epoch 66/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0297 - acc: 0.9906 - val_loss: 0.0270 - val_acc: 0.9916\n",
      "Epoch 67/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "Epoch 68/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.0267 - val_acc: 0.9914\n",
      "Epoch 69/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0288 - acc: 0.9906 - val_loss: 0.0271 - val_acc: 0.9918\n",
      "Epoch 70/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0296 - acc: 0.9899 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "Epoch 71/100\n",
      "20000/20000 [==============================] - 4s 210us/step - loss: 0.0287 - acc: 0.9909 - val_loss: 0.0281 - val_acc: 0.9910\n",
      "Epoch 72/100\n",
      "20000/20000 [==============================] - 4s 209us/step - loss: 0.0305 - acc: 0.9906 - val_loss: 0.0269 - val_acc: 0.9914\n",
      "Epoch 73/100\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.0293 - acc: 0.9902 - val_loss: 0.0265 - val_acc: 0.9916\n",
      "Epoch 74/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0289 - acc: 0.9901 - val_loss: 0.0268 - val_acc: 0.9914\n",
      "Epoch 75/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0282 - acc: 0.9909 - val_loss: 0.0263 - val_acc: 0.9918\n",
      "Epoch 76/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0286 - acc: 0.9905 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "Epoch 77/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0267 - acc: 0.9911 - val_loss: 0.0267 - val_acc: 0.9914\n",
      "Epoch 78/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0285 - acc: 0.9908 - val_loss: 0.0268 - val_acc: 0.9914\n",
      "Epoch 79/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0274 - acc: 0.9905 - val_loss: 0.0265 - val_acc: 0.9914\n",
      "Epoch 80/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0294 - acc: 0.9905 - val_loss: 0.0267 - val_acc: 0.9914\n",
      "Epoch 81/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0294 - acc: 0.9902 - val_loss: 0.0267 - val_acc: 0.9914\n",
      "Epoch 82/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0267 - val_acc: 0.9914\n",
      "Epoch 83/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0286 - acc: 0.9907 - val_loss: 0.0270 - val_acc: 0.9916\n",
      "Epoch 84/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0266 - val_acc: 0.9914\n",
      "Epoch 85/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0277 - acc: 0.9919 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "Epoch 86/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0253 - acc: 0.9913 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "Epoch 87/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0243 - acc: 0.9915 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Epoch 88/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0262 - acc: 0.9910 - val_loss: 0.0262 - val_acc: 0.9916\n",
      "Epoch 89/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.0267 - val_acc: 0.9918\n",
      "Epoch 90/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0282 - acc: 0.9899 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "Epoch 91/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0279 - acc: 0.9914 - val_loss: 0.0265 - val_acc: 0.9916\n",
      "Epoch 92/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0261 - acc: 0.9914 - val_loss: 0.0267 - val_acc: 0.9916\n",
      "Epoch 93/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0266 - val_acc: 0.9914\n",
      "Epoch 94/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0259 - acc: 0.9909 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Epoch 95/100\n",
      "20000/20000 [==============================] - 4s 206us/step - loss: 0.0279 - acc: 0.9909 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "Epoch 96/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0253 - acc: 0.9918 - val_loss: 0.0265 - val_acc: 0.9914\n",
      "Epoch 97/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0263 - val_acc: 0.9916\n",
      "Epoch 98/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0261 - val_acc: 0.9920\n",
      "Epoch 99/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0257 - acc: 0.9914 - val_loss: 0.0266 - val_acc: 0.9916\n",
      "Epoch 100/100\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.0250 - acc: 0.9916 - val_loss: 0.0266 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f630ffa2668>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_split=0.2, callbacks=[TensorBoard(log_dir='mytensorboard/4')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 53us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "import pandas as pd\n",
    "from ipykernel import kernelapp as app\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"test2\", (224, 224), shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('submission.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 133.00 483.00\" width=\"133pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 129,-479 129,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140066849990528 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140066849990528</title>\n",
       "<polygon fill=\"none\" points=\"-7.10543e-15,-438.5 -7.10543e-15,-474.5 125,-474.5 125,-438.5 -7.10543e-15,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-452.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140066849990304 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140066849990304</title>\n",
       "<polygon fill=\"none\" points=\"-7.10543e-15,-365.5 -7.10543e-15,-401.5 125,-401.5 125,-365.5 -7.10543e-15,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-379.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140066849990528&#45;&gt;140066849990304 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140066849990528-&gt;140066849990304</title>\n",
       "<path d=\"M62.5,-438.313C62.5,-430.289 62.5,-420.547 62.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-411.529 62.5,-401.529 59.0001,-411.529 66.0001,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140066849993224 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140066849993224</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-292.5 11.5,-328.5 113.5,-328.5 113.5,-292.5 11.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-306.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140066849990304&#45;&gt;140066849993224 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140066849990304-&gt;140066849993224</title>\n",
       "<path d=\"M62.5,-365.313C62.5,-357.289 62.5,-347.547 62.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-338.529 62.5,-328.529 59.0001,-338.529 66.0001,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140063458894568 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140063458894568</title>\n",
       "<polygon fill=\"none\" points=\"-7.10543e-15,-219.5 -7.10543e-15,-255.5 125,-255.5 125,-219.5 -7.10543e-15,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-233.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 140066849993224&#45;&gt;140063458894568 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140066849993224-&gt;140063458894568</title>\n",
       "<path d=\"M62.5,-292.313C62.5,-284.289 62.5,-274.547 62.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-265.529 62.5,-255.529 59.0001,-265.529 66.0001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140066863438312 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140066863438312</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-146.5 11.5,-182.5 113.5,-182.5 113.5,-146.5 11.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-160.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140063458894568&#45;&gt;140066863438312 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140063458894568-&gt;140066863438312</title>\n",
       "<path d=\"M62.5,-219.313C62.5,-211.289 62.5,-201.547 62.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-192.529 62.5,-182.529 59.0001,-192.529 66.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140066844976520 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140066844976520</title>\n",
       "<polygon fill=\"none\" points=\"-7.10543e-15,-73.5 -7.10543e-15,-109.5 125,-109.5 125,-73.5 -7.10543e-15,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-87.8\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 140066863438312&#45;&gt;140066844976520 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140066863438312-&gt;140066844976520</title>\n",
       "<path d=\"M62.5,-146.313C62.5,-138.289 62.5,-128.547 62.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-119.529 62.5,-109.529 59.0001,-119.529 66.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140063457979360 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140063457979360</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-0.5 11.5,-36.5 113.5,-36.5 113.5,-0.5 11.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-14.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 140066844976520&#45;&gt;140063457979360 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140066844976520-&gt;140063457979360</title>\n",
       "<path d=\"M62.5,-73.3129C62.5,-65.2895 62.5,-55.5475 62.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-46.5288 62.5,-36.5288 59.0001,-46.5289 66.0001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "import pydot\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
